实验步骤：
Part-1 I/O实验部分
1、	部署实验用的hadoop-2.0.0-nkfs集群，详见文档2；(注意在core-site.xml中设置n、k值)
2、	写入实验数据 (写入nkfs与hdfs的时间对比)
time ./bin/hdfs dfs -put /home/fengqingqing/exp/data/OANC-GrAF/data/large_txt nkfs:///
记录数据写入时间
完成后可用 ./bin/hdfs dfs -ls hdfs:///nkfs_base 查看到输入数据被放在hdfs:///nkfs_base/origin/目录下
3、读出数据（记录数据读时间）（从nkfs与hdfs读出的时间对比）
3、	运行time ./bin/hadoop  cn.ict.magicube.fs.shell.NKFSShell  -doraid 执行数据分片
记录数据分片时间
4、	运行 ./bin/hdfs dfs -ls hdfs:///nkfs_base/parities 可查看各个文件分片，分片之后的原始数据被放在hdfs:///nkfs_base/parities/xxx/part-xxx-xxx/origin目录下，各个分片分别为：
hdfs:///nkfs_base/parities/xxx/part-xxx-xxx/parity_x
运行./bin/hadoop  cn.ict.magicube.fs.shell.NKFSShell  -showlocations nkfs:/// 可查看各分片所在位置
5、（人为破坏掉部分分片，造成数据丢失）：
./bin/hdfs dfs -rm hdfs:///nkfs_base/parities/xxx/part-xxx-xxx/parity_x
6、	运行time ./bin/hadoop  cn.ict.magicube.fs.shell.NKFSShell –dofix 可还原受损文件 
记录数据恢复时间
7、用time ./bin/hdfs dfs -get hdfs:///nkfs_base/parities/xxx/part-xxx-xxx/origin /tmp/xxx获取恢复之后的数据到本地
8、可用md5sum效验恢复的数据，与之前的原始数据对比，可得到一致的效验结果。
9、执行完以上操作之后，执行./bin/hadoop  cn.ict.magicube.fs.shell.NKFSShell –reset，运行的结果，删除hdfs:///nkfs_base下所有内容

Part-2  job执行实验部分
Wordcount
1、	nkfs上运行wordcount
time ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.0-alpha.jar wordcount nkfs:///2g out2x
real    0m43.965s
user    0m3.864s
sys     0m0.192s
或者
./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.0-alpha.jar wordcount hdfs:///nkfs_base/origin/xxx output

2、	在hdfs上运行wordcount
time ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.0-alpha.jar wordcount hdfs:///input out2gh
real    0m43.957s
user    0m3.858s
sys     0m0.193s

其它jobs:

3、	sort(in hdfs)：http://www.hadooper.cn/dct/page/65777
./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.0-alpha.jar randomwriter rand  生成随机文件
time ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.0-alpha.jar sort rand rand2sort 执行hadoop sort并记录完成时间
real    26m33.907s
user    0m7.439s
sys     0m0.371s
第一个命令会在rand 目录的生成没有排序的数据。第二个命令会读数据，排序，然后写入rand-sort 目录

4、Grep 例子从文本文件中，抽取匹配的字符串，并计算出现过多少次
http://www.hadooper.cn/dct/page/65776
为运行示例，输入以下命令:
bin/hadoop org.apache.hadoop.examples.Grep <indir> <outdir> <regex> [<group>]
（操作示例）:
time ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.0-alpha.jar grep hdfs:///input goutput '[a-z.]+'

将输入文件拷贝到分布式文件系统：
$ bin/hadoop fs -put conf input
运行发行版提供的示例程序：
$ bin/hadoop jar hadoop-*-examples.jar grep input output 'dfs[a-z.]+'

查看输出文件：
将输出文件从分布式文件系统拷贝到本地文件系统查看：
$ bin/hadoop fs -get output output
$ cat output/*
或者
在分布式文件系统上查看输出文件：
$ bin/hadoop fs -cat output/*

5、terasort
http://blog.csdn.net/leafy1980/article/details/6633828
操作过程如下：
在hdfs生成2g测试数据：
time ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.0-alpha.jar teregen 21474836 /terasort/input2g
real    0m42.833s
user    0m3.781s
sys     0m0.173s
time ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.0-alpha.jar terasort /terasort/input2g /terasort/output2g
real    1m34.709s
user    0m5.187s
sys     0m0.273s

在nkfs系统中：
生成2g数据
time ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.0-alpha.jar teragen 21474836 nkfs:///terasort/input2g
real    0m37.851s
user    0m3.800s
sys     0m0.178s
执行terasort
time ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.0.0-alpha.jar teragen 21474836 nkfs:///terasort/input2g
real    1m37.817s
user    0m5.175s
sys     0m0.257s

在hadoop里，利用TeraGen生成排序输入数据的命令格式是这样的：
bin/hadoop jar hadoop-0.19.2-examples.jar teragen 10000000000 /terasort/input1TB  
注意，teragen后的数值单位是行数；因为每行100个字节，所以如果要产生1T的数据量，则这个数值应为1T/100=10000000000(10个0)。
运行TeraSort的命令是这样的：
bin/hadoop jar hadoop-0.19.2-examples.jar terasort /terasort/input1TB /terasort/output1TB
运行后，我们可以看到会起m个mapper（取决于输入文件个数）和r个reducer（取决于设置项：mapred.reduce.tasks），排好序的结果存放在/terasort/output1TB目录。

更多关于benchmark的介绍文章：
http://baidutech.blog.51cto.com/4114344/743496

注：HDFS文件操作：http://yu06206.iteye.com/blog/1396376
在HDFS上创建目录
命令：user@namenode:hadoop$ bin/hadoop dfs -mkdir /文件名
上传一个文件到HDFS
命令：user@namenode:hadoop$ bin/hadoop dfs -put 文件名 /user/yourUserName/
目录 myfiles/能够这样被拷贝进HDFS中： 
Shell代码 
   1. someone@anynode:hadoop$ bin/hadoop -put myfiles /user/myUsername 
-put  的另外一种写法是 -copyFromLocal. 它们的功能和用法是一样的。
从 HDFS 中导出数据 
命令：user@namenode:hadoop$ bin/hadoop dfs -cat foo 
Step 2: 将HDFS中的文件拷贝到本地系统中。 
"get"命令有跟"put"命令相反的功能，它能够将HDFS中文件或目录拷贝到本地系统中。“get”命令的别名叫做copyToLocal. 


Shell代码 
   1. someone@anynode:hadoop$ bin/hadoop dfs -get foo localFoo 
跟 "put"命令一样，"get"操作既可以操作文件，也可以操作目录。
HDFS全局状态信息
命令：bin/hadoop dfsadmin -report
获取帮助 - 跟 dfs 模块是一样的, 你可以使用 bin/hadoop dfsadmin -help命令来获取特定的命令的一些用法。


附录：
gb 28物理集群上的实验结果记录
time ./bin/hdfs dfs -put /home/fengqingqing/exp/data/OANC-GrAF/data/2g nkfs:///
real    0m43.084s
user    0m14.463s
sys     0m3.820s
time ./bin/hdfs dfs -get hdfs:///nkfs_base/origin/2g /tmp/
real    0m21.602s
user    0m10.530s
sys     0m6.239s
在hdfs上执行同样操作：
time ./bin/hdfs dfs -put /home/fengqingqing/exp/data/OANC-GrAF/data/2g hdfs:///input
real    0m23.780s
user    0m13.819s
sys     0m2.593s

